{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f628587-ec02-4017-b657-d2d7629a297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Auto-labeled classes (kept >= 5 samples): ['bash', 'css', 'html', 'java', 'javascript', 'matlab', 'python', 'sql', 'typescript']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Model: C:\\Users\\sagni\\Downloads\\Code Generator\\cg_model.joblib\n",
      "[SAVE] Label map: C:\\Users\\sagni\\Downloads\\Code Generator\\cg_label_map.json\n",
      "[OUT] Saved: C:\\Users\\sagni\\Downloads\\Code Generator\\cg_predictions_test.csv\n",
      "[OUT] Saved: C:\\Users\\sagni\\Downloads\\Code Generator\\cg_predictions_test.json\n",
      "=== DONE ===\n",
      "Acc: 0.5094 | Macro-F1: 0.2407\n",
      "Artifacts in: C:\\Users\\sagni\\Downloads\\Code Generator\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, warnings\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, Tuple, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, classification_report\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ------------------ USER PATHS ------------------\n",
    "CSV_PATH = r\"C:\\Users\\sagni\\Downloads\\Code Generator\\archive\\train.csv\"\n",
    "OUT_DIR  = r\"C:\\Users\\sagni\\Downloads\\Code Generator\"\n",
    "\n",
    "# Optional: if you DO have a ground-truth label column (e.g., \"lang\", \"category\")\n",
    "LABEL_OVERRIDE: Optional[str] = None   # e.g., \"lang\"\n",
    "\n",
    "# Optional: predict on an external file (.txt/.csv/.json); leave None to skip\n",
    "INFER_SOURCE: Optional[str] = None\n",
    "# Examples:\n",
    "# INFER_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Code Generator\\my_eval.csv\"\n",
    "# INFER_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Code Generator\\snippets.txt\"\n",
    "# INFER_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Code Generator\\batch.json\"\n",
    "\n",
    "# ------------------ CONSTANTS ------------------\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.15\n",
    "VALID_SIZE = 0.15  # of remaining after test split\n",
    "AUTO_LABEL_MIN_SAMPLES_PER_CLASS = 5\n",
    "\n",
    "TEXT_CANDS = [\n",
    "    \"instruction\",\"prompt\",\"question\",\"title\",\"description\",\"desc\",\"nl\",\n",
    "    \"input\",\"context\",\"spec\",\"problem\",\"statement\",\"query\",\"utterance\"\n",
    "]\n",
    "LABEL_CANDS = [\n",
    "    \"label\",\"category\",\"class\",\"target\",\"task\",\"task_id\",\"task_type\",\n",
    "    \"language\",\"lang\",\"topic\",\"difficulty\",\"level\",\"dataset\",\"source\",\"tag\",\"type\"\n",
    "]\n",
    "CODE_CANDS = [\"output\",\"code\",\"completion\",\"solution\",\"program\",\"answer\",\"response\"]\n",
    "\n",
    "MODEL_PATH    = os.path.join(OUT_DIR, \"cg_model.joblib\")\n",
    "LABELMAP_PATH = os.path.join(OUT_DIR, \"cg_label_map.json\")\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def ensure_out():\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def read_csv_any(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    for kwargs in [{}, {\"encoding\":\"utf-8\",\"errors\":\"ignore\"}, {\"encoding\":\"latin-1\"}, {\"engine\":\"python\"}]:\n",
    "        try:\n",
    "            return pd.read_csv(path, **kwargs)\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise RuntimeError(f\"Could not read CSV: {path}\")\n",
    "\n",
    "def sanitize_colname(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9_]+\", \"_\", s.strip()) or \"label\"\n",
    "\n",
    "# ------------------ LANGUAGE DETECTION (heuristic) ------------------\n",
    "LANG_PATTERNS = [\n",
    "    (\"html\", re.compile(r\"<!doctype html>|<html|</html>|<div|<span|<body\", re.I)),\n",
    "    (\"css\", re.compile(r\"{\\s*[^}]*:\\s*[^}]+}\", re.I)),\n",
    "    (\"sql\", re.compile(r\"\\b(select|insert|update|delete|create table|where|join|group by|order by)\\b\", re.I)),\n",
    "    (\"bash\", re.compile(r\"^#!\\/bin\\/bash|(^|\\n)\\s*(echo|grep|awk|sed|export|cd )\", re.I)),\n",
    "    (\"python\", re.compile(r\"\\b(def |import |from |lambda|print\\(|self\\b|async def|raise |except |try:)\", re.I)),\n",
    "    (\"typescript\", re.compile(r\"\\binterface\\b|\\btype\\s+\\w+\\s*=\\s*|\\bas\\s+\\w+|:\\s*(string|number|boolean)\\b\", re.I)),\n",
    "    (\"javascript\", re.compile(r\"\\b(function |console\\.log|=>|var |let |const |export |import )\", re.I)),\n",
    "    (\"java\", re.compile(r\"\\b(public class|System\\.out\\.println|static void main|package\\s+\\w+;|import java\\.)\", re.I)),\n",
    "    (\"cpp\", re.compile(r\"#include\\s*<[^>]+>|std::|using namespace std|cout\\s*<<\", re.I)),\n",
    "    (\"csharp\", re.compile(r\"\\busing System;|Console\\.Write(Line|)\\(|namespace\\s+\\w+|public class Program\\b\", re.I)),\n",
    "    (\"go\", re.compile(r\"\\bpackage main\\b|\\bfunc main\\(|\\bfmt\\.\", re.I)),\n",
    "    (\"rust\", re.compile(r\"\\bfn main\\(\\)|println!|let mut|use std::\", re.I)),\n",
    "    (\"php\", re.compile(r\"<\\?php|echo\\s+\\$|->\", re.I)),\n",
    "    (\"ruby\", re.compile(r\"\\bdef\\b.*\\n.*\\n.*\\bend\\b|\\bputs\\b\", re.I)),\n",
    "    (\"kotlin\", re.compile(r\"\\bfun main\\(|\\bval\\s+\\w+|\\bvar\\s+\\w+|\\bprintln\\(\", re.I)),\n",
    "    (\"swift\", re.compile(r\"\\bimport Foundation\\b|\\bprint\\(|\\blet\\s+\\w+|\\bvar\\s+\\w+|\\bfunc\\b\", re.I)),\n",
    "    (\"r\", re.compile(r\"<-|\\blibrary\\(|\\bdata\\.frame\\(\", re.I)),\n",
    "    (\"matlab\", re.compile(r\"^function\\s+\\[?.*\\]?\\s*=\\s*\\w+\\(|\\bplot\\(|\\%\\s\", re.I)),\n",
    "]\n",
    "\n",
    "def detect_language_from_code(code: str) -> str:\n",
    "    if not isinstance(code, str) or not code.strip():\n",
    "        return \"unknown\"\n",
    "    for name, pat in LANG_PATTERNS:\n",
    "        if pat.search(code):\n",
    "            return name\n",
    "    return \"unknown\"\n",
    "\n",
    "# ------------------ COLUMN DETECTION ------------------\n",
    "def detect_columns(df: pd.DataFrame) -> Tuple[pd.Series, Optional[pd.Series], str, Optional[str], Optional[str]]:\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    # text feature column\n",
    "    tcol = next((lower[c] for c in TEXT_CANDS if c in lower), None)\n",
    "    if tcol is None:\n",
    "        obj = [c for c in df.columns if df[c].dtype == object]\n",
    "        if not obj:\n",
    "            raise ValueError(\"No text-like column found. Add e.g., 'instruction' or 'prompt'.\")\n",
    "        tcol = obj[0]\n",
    "    text = df[tcol].astype(str).fillna(\"\").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    text = text[text != \"\"]\n",
    "    df = df.loc[text.index]\n",
    "\n",
    "    # label column\n",
    "    lcol = None\n",
    "    if LABEL_OVERRIDE and LABEL_OVERRIDE in df.columns:\n",
    "        lcol = LABEL_OVERRIDE\n",
    "    else:\n",
    "        lcol = next((lower[c] for c in LABEL_CANDS if c in lower), None)\n",
    "\n",
    "    # code column (for auto-labeling)\n",
    "    ccol = next((lower[c] for c in CODE_CANDS if c in lower), None)\n",
    "\n",
    "    labels_raw = df[lcol].loc[text.index] if lcol else None\n",
    "    return text, labels_raw, tcol, lcol, ccol\n",
    "\n",
    "# ------------------ MODEL ------------------\n",
    "def build_pipeline() -> Pipeline:\n",
    "    return Pipeline(steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            ngram_range=(1,2),      # uni+bi-grams\n",
    "            min_df=2,\n",
    "            max_features=300_000,\n",
    "            strip_accents=\"unicode\"\n",
    "        )),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            max_iter=400,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight=\"balanced\",\n",
    "            multi_class=\"auto\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# ------------------ PRED/IO ------------------\n",
    "def save_predictions_dataframe(df: pd.DataFrame, base_name: str):\n",
    "    csv_path  = os.path.join(OUT_DIR, f\"{base_name}.csv\")\n",
    "    json_path = os.path.join(OUT_DIR, f\"{base_name}.json\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        payload = {\n",
    "            \"created_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"items\": df.to_dict(orient=\"records\"),\n",
    "            \"summary\": {\n",
    "                \"total\": int(len(df)),\n",
    "                \"pred_counts\": {k: int(v) for k, v in df[\"pred_label\"].value_counts().to_dict().items()}\n",
    "            }\n",
    "        }\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "    print(\"[OUT] Saved:\", csv_path)\n",
    "    print(\"[OUT] Saved:\", json_path)\n",
    "\n",
    "def load_texts_for_infer(path: str) -> List[str]:\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return [ln.strip() for ln in f if ln.strip()]\n",
    "    if ext == \".json\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, dict) and \"items\" in data:\n",
    "            return [d.get(\"text\",\"\") for d in data[\"items\"] if str(d.get(\"text\",\"\")).strip()]\n",
    "        if isinstance(data, dict) and \"messages\" in data:\n",
    "            return [m.get(\"text\",\"\") if isinstance(m,dict) else str(m) for m in data[\"messages\"] if str(m).strip()]\n",
    "        if isinstance(data, list):\n",
    "            return [d.get(\"text\",\"\") if isinstance(d,dict) else str(d) for d in data if str(d).strip()]\n",
    "        raise ValueError(\"Unsupported JSON schema. Use list, or {'messages':[{'text':...}]}, or {'items':[{'text':...}]} .\")\n",
    "    if ext == \".csv\":\n",
    "        df = read_csv_any(path)\n",
    "        lower = {c.lower(): c for c in df.columns}\n",
    "        # prefer code-like column if present\n",
    "        for c in CODE_CANDS + TEXT_CANDS:\n",
    "            if c in lower:\n",
    "                col = lower[c]\n",
    "                return df[col].astype(str).fillna(\"\").str.strip().tolist()\n",
    "        # fallback: first column\n",
    "        return df.iloc[:,0].astype(str).fillna(\"\").str.strip().tolist()\n",
    "    raise ValueError(\"Supported external inference files: .txt, .csv, .json\")\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "def main():\n",
    "    ensure_out()\n",
    "    df = read_csv_any(CSV_PATH)\n",
    "\n",
    "    # Detect columns\n",
    "    text, labels_raw, tcol, lcol, ccol = detect_columns(df)\n",
    "    labels_source = \"provided_column\"\n",
    "\n",
    "    # If no label column, auto-label by language using code column\n",
    "    if labels_raw is None:\n",
    "        if ccol is None:\n",
    "            raise ValueError(\n",
    "                \"No label-like column found AND no code column to auto-label from.\\n\"\n",
    "                \"Fix: set LABEL_OVERRIDE to your label column name, or ensure a code column exists \"\n",
    "                \"(one of: output/code/completion/solution/program/answer/response).\"\n",
    "            )\n",
    "        codes = df.loc[text.index, ccol].astype(str).fillna(\"\")\n",
    "        auto_labels = codes.map(detect_language_from_code)\n",
    "        # keep known languages only\n",
    "        mask_known = auto_labels != \"unknown\"\n",
    "        text = text[mask_known]; auto_labels = auto_labels[mask_known]\n",
    "        if auto_labels.nunique() < 2:\n",
    "            raise ValueError(\n",
    "                f\"Auto-labeling produced <2 classes (found: {sorted(auto_labels.unique().tolist())}). \"\n",
    "                \"Need >=2 classes to train and evaluate.\"\n",
    "            )\n",
    "        # drop tiny classes\n",
    "        vc = auto_labels.value_counts()\n",
    "        keep = vc[vc >= AUTO_LABEL_MIN_SAMPLES_PER_CLASS].index\n",
    "        text = text[auto_labels.isin(keep)]\n",
    "        auto_labels = auto_labels[auto_labels.isin(keep)]\n",
    "        labels_raw = auto_labels\n",
    "        labels_source = \"auto:lang_from_code\"\n",
    "        # Use the code itself as features for better signal\n",
    "        text = df.loc[text.index, ccol].astype(str).fillna(\"\")\n",
    "        print(f\"[INFO] Auto-labeled classes (kept >= {AUTO_LABEL_MIN_SAMPLES_PER_CLASS} samples):\", sorted(keep.tolist()))\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_all = le.fit_transform(labels_raw.astype(str))\n",
    "    id2label = {int(i): str(l) for i, l in enumerate(le.classes_)}\n",
    "\n",
    "    # Split\n",
    "    X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "        text, y_all, test_size=TEST_SIZE, stratify=y_all,\n",
    "        random_state=RANDOM_STATE, shuffle=True\n",
    "    )\n",
    "    valid_frac_of_tmp = VALID_SIZE / (1.0 - TEST_SIZE)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_tmp, y_tmp, test_size=valid_frac_of_tmp, stratify=y_tmp,\n",
    "        random_state=RANDOM_STATE, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Build & fit on TRAIN+VALID\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            ngram_range=(1,2),\n",
    "            min_df=2,\n",
    "            max_features=300_000,\n",
    "            strip_accents=\"unicode\"\n",
    "        )),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            max_iter=400,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight=\"balanced\",\n",
    "            multi_class=\"auto\"\n",
    "        ))\n",
    "    ])\n",
    "    pipe.fit(pd.concat([X_train, X_valid]), np.concatenate([y_train, y_valid]))\n",
    "\n",
    "    # Save model + label map\n",
    "    dump(pipe, MODEL_PATH)\n",
    "    with open(LABELMAP_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"id2label\": {str(k): v for k, v in id2label.items()},\n",
    "                   \"label2id\": {str(v): int(k) for k, v in id2label.items()}},\n",
    "                  f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"[SAVE] Model:\", MODEL_PATH)\n",
    "    print(\"[SAVE] Label map:\", LABELMAP_PATH)\n",
    "\n",
    "    # Evaluate on TEST\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    proba = pipe.predict_proba(X_test) if hasattr(pipe[-1], \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # Report\n",
    "    report_txt = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[id2label[i] for i in sorted(set(y_test) | set(y_pred))],\n",
    "        zero_division=0\n",
    "    )\n",
    "    with open(os.path.join(OUT_DIR, \"cg_classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report_txt)\n",
    "\n",
    "    # Metrics JSON\n",
    "    metrics = {\n",
    "        \"created_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"source_csv\": CSV_PATH,\n",
    "        \"labels_source\": labels_source,\n",
    "        \"text_column_used\": tcol,\n",
    "        \"label_column_used\": (lcol if labels_source == \"provided_column\" else \"auto:lang_from_code\"),\n",
    "        \"sizes\": {\"train\": int(len(X_train)), \"valid\": int(len(X_valid)), \"test\": int(len(X_test))},\n",
    "        \"test_metrics\": {\n",
    "            \"accuracy\": round(float(acc), 4),\n",
    "            \"macro_precision\": round(float(p), 4),\n",
    "            \"macro_recall\": round(float(r), 4),\n",
    "            \"macro_f1\": round(float(f1), 4)\n",
    "        },\n",
    "        \"artifacts\": {\n",
    "            \"model_path\": MODEL_PATH,\n",
    "            \"label_map_path\": LABELMAP_PATH,\n",
    "            \"classification_report_txt\": os.path.join(OUT_DIR, \"cg_classification_report.txt\"),\n",
    "            \"predictions_csv\": os.path.join(OUT_DIR, \"cg_predictions_test.csv\")\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, \"cg_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Save per-row TEST predictions (with probabilities)\n",
    "    preds_test = {\n",
    "        \"text\": X_test.values,\n",
    "        \"y_true\": [id2label[int(i)] for i in y_test],\n",
    "        \"pred_label\": [id2label[int(i)] for i in y_pred]\n",
    "    }\n",
    "    if proba is not None:\n",
    "        for i in range(proba.shape[1]):\n",
    "            lab = sanitize_colname(id2label[i])\n",
    "            preds_test[f\"p_{lab}\"] = proba[:, i]\n",
    "    test_df = pd.DataFrame(preds_test)\n",
    "    save_predictions_dataframe(test_df, base_name=\"cg_predictions_test\")\n",
    "\n",
    "    # ---------------- External inference (optional) ----------------\n",
    "    if INFER_SOURCE is not None:\n",
    "        if not os.path.exists(INFER_SOURCE):\n",
    "            raise FileNotFoundError(INFER_SOURCE)\n",
    "        texts = load_texts_for_infer(INFER_SOURCE)\n",
    "        texts = [t for t in texts if str(t).strip()]\n",
    "        if not texts:\n",
    "            print(\"[WARN] No texts to predict in external file.\")\n",
    "        else:\n",
    "            y_ext = pipe.predict(texts)\n",
    "            proba_ext = pipe.predict_proba(texts) if hasattr(pipe[-1], \"predict_proba\") else None\n",
    "\n",
    "            rows = {\"text\": texts, \"pred_label\": [id2label[int(i)] for i in y_ext]}\n",
    "            if proba_ext is not None:\n",
    "                for i in range(proba_ext.shape[1]):\n",
    "                    lab = sanitize_colname(id2label[i])\n",
    "                    rows[f\"p_{lab}\"] = proba_ext[:, i]\n",
    "            ext_df = pd.DataFrame(rows)\n",
    "            save_predictions_dataframe(ext_df, base_name=\"cg_predictions_external\")\n",
    "            # Append run info\n",
    "            summ_path = os.path.join(OUT_DIR, \"cg_metrics.json\")\n",
    "            try:\n",
    "                with open(summ_path, \"r\", encoding=\"utf-8\") as f: meta = json.load(f)\n",
    "            except Exception:\n",
    "                meta = {}\n",
    "            meta.setdefault(\"external_infer_runs\", []).append({\n",
    "                \"run_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                \"source_file\": INFER_SOURCE,\n",
    "                \"count\": int(len(ext_df))\n",
    "            })\n",
    "            with open(summ_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"[INFER] Ran predictions on: {INFER_SOURCE}\")\n",
    "\n",
    "    print(\"=== DONE ===\")\n",
    "    print(\"Acc:\", round(acc,4), \"| Macro-F1:\", round(f1,4))\n",
    "    print(\"Artifacts in:\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802dfbc-ab6d-4fd9-9200-5d9053fc8495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
